{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jJdDiQiRXFY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "!pip install mtcnn\n",
        "!pip install opencv-python\n",
        "\n",
        "# This will list the files in 'My Drive', including the shortcuts.\n",
        "drive_root = '/content/drive/MyDrive/'\n",
        "os.listdir(drive_root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to get frames for original & manipulated and perfrom mtcnn"
      ],
      "metadata": {
        "id": "_VOZrfRiRloT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "from mtcnn import MTCNN\n",
        "\n",
        "detector = MTCNN()\n",
        "log_file = \"processed_frames.log\"\n",
        "\n",
        "# Load already processed paths\n",
        "processed = set()\n",
        "if os.path.exists(log_file):\n",
        "    with open(log_file, 'r') as f:\n",
        "        processed = set(line.strip() for line in f.readlines())\n",
        "\n",
        "def process_frame(frame_path):\n",
        "    if frame_path in processed:\n",
        "        return False  # Not newly processed\n",
        "\n",
        "    try:\n",
        "        image = cv2.imread(frame_path)\n",
        "        if image is None:\n",
        "            return False\n",
        "\n",
        "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        faces = detector.detect_faces(rgb_image)\n",
        "\n",
        "        for face in faces:\n",
        "            confidence = face['confidence']\n",
        "            box = face['box']\n",
        "            keypoints = face['keypoints']\n",
        "\n",
        "            if confidence < 0.90 or box[2] < 50 or box[3] < 50:\n",
        "                continue\n",
        "            if not all(k in keypoints for k in ['left_eye', 'right_eye', 'nose', 'mouth_left', 'mouth_right']):\n",
        "                continue\n",
        "            if abs(keypoints['left_eye'][0] - keypoints['right_eye'][0]) < 15:\n",
        "                continue\n",
        "\n",
        "            x, y, w, h = box\n",
        "            x, y = max(0, x), max(0, y)\n",
        "            cropped_face = image[y:y+h, x:x+w]\n",
        "\n",
        "            cv2.rectangle(cropped_face, (0, 0), (w, h), (0, 255, 0), 2)\n",
        "            cv2.imwrite(frame_path, cropped_face)\n",
        "\n",
        "            with open(log_file, 'a') as logf:\n",
        "                logf.write(frame_path + '\\n')\n",
        "            processed.add(frame_path)\n",
        "\n",
        "            return True  # Newly processed\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ðŸ’¥ Error processing {frame_path}: {e}\")\n",
        "\n",
        "    time.sleep(0.05)\n",
        "    return False\n",
        "\n",
        "def process_all_images(directory_path, max_folders=100):\n",
        "    folders_processed = 0\n",
        "\n",
        "    for folder_name in sorted(os.listdir(directory_path)):\n",
        "        if folders_processed >= max_folders:\n",
        "            break\n",
        "\n",
        "        folder_path = os.path.join(directory_path, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            jpg_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.jpg')])\n",
        "            newly_processed_in_folder = 0\n",
        "            total_in_folder = len(jpg_files)\n",
        "\n",
        "            for file_name in jpg_files:\n",
        "                file_path = os.path.join(folder_path, file_name)\n",
        "                if process_frame(file_path):\n",
        "                    newly_processed_in_folder += 1\n",
        "\n",
        "            print(f\"ðŸ“‚ Done with folder {folder_name}: {total_in_folder} total, {newly_processed_in_folder} newly processed\")\n",
        "            folders_processed += 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    directory_path = '/content/drive/MyDrive/FaceForensicsData/frames_for_original_videos'\n",
        "    process_all_images(directory_path, max_folders=100)\n",
        "    print(f\"ðŸŽ‰ Done! Processed up to 100 folders.\")\n"
      ],
      "metadata": {
        "id": "Wds63R5mRgkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rWy-We-eSZ69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "get the labels"
      ],
      "metadata": {
        "id": "Dv2mt6HeR13t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "put them into v1 and v2 inception resnet"
      ],
      "metadata": {
        "id": "mjgX3HWGSbHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Load model\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "\n",
        "# Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "# Base paths (Limit to only one video from each category)\n",
        "data_sources = {\n",
        "    \"/content/drive/MyDrive/FaceForensicsData/frames_for_original_videos\": 0,   # Real\n",
        "    \"/content/drive/MyDrive/FaceForensicsData/frames_for_FaceSwap\": 1 # Fake\n",
        "}\n",
        "\n",
        "# Hold all embeddings and labels\n",
        "all_embeddings = []\n",
        "all_labels = []\n",
        "\n",
        "# Process only the first video from both real and fake datasets\n",
        "for folder_path, label in data_sources.items():\n",
        "    # Select the first video folder from the directory (only one video folder)\n",
        "    video_folders = sorted(os.listdir(folder_path))[:1]  # Limit to the first folder\n",
        "\n",
        "    for video_folder in tqdm(video_folders, desc=f\"Processing {folder_path}\"):\n",
        "        video_path = os.path.join(folder_path, video_folder)\n",
        "        if not os.path.isdir(video_path):\n",
        "            continue\n",
        "\n",
        "        # Process all frames (100 frames) inside this folder\n",
        "        for img_name in sorted(os.listdir(video_path)):\n",
        "            if not img_name.endswith('.jpg'):\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(video_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img_pil = Image.fromarray(img_rgb)\n",
        "            img_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                embedding = model(img_tensor).cpu().numpy().flatten()  # shape: (512,)\n",
        "\n",
        "            # Append the embedding and label to lists\n",
        "            all_embeddings.append(embedding)\n",
        "            all_labels.append(label)\n",
        "\n",
        "# Convert to arrays\n",
        "X = np.array(all_embeddings)  # shape: (num_images, 512)\n",
        "y = np.array(all_labels)      # shape: (num_images,)\n",
        "\n",
        "# Save embeddings and labels to Google Drive\n",
        "save_path = '/content/drive/MyDrive/embeddings_and_labels/'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save embeddings and labels to Google Drive\n",
        "np.save(os.path.join(save_path, \"test_embeddings.npy\"), X)\n",
        "np.save(os.path.join(save_path, \"test_labels.npy\"), y)\n",
        "\n",
        "print(f\"âœ… Finished processing. Embeddings shape: {X.shape}, Labels shape: {y.shape}\")\n"
      ],
      "metadata": {
        "id": "9sbdp11TSe_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get the labels and save them"
      ],
      "metadata": {
        "id": "Kf01cwrmSlAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "from tqdm import tqdm\n",
        "from itertools import islice  # Import for limiting folder count\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Load model\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "\n",
        "# Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "# Base paths\n",
        "data_sources = {\n",
        "    \"/content/drive/MyDrive/FaceForensicsData/frames_for_original_videos\": 0,   # Real\n",
        "    \"/content/drive/MyDrive/FaceForensicsData/frames_for_FaceSwap\": 1 # Fake\n",
        "}\n",
        "\n",
        "# Hold all embeddings and labels\n",
        "all_embeddings = []\n",
        "all_labels = []\n",
        "\n",
        "# Process only the first 100 folders from both real and fake datasets\n",
        "for folder_path, label in data_sources.items():\n",
        "    # Use islice to limit the number of folders processed (100 folders from each category)\n",
        "    video_folders = list(islice(sorted(os.listdir(folder_path)), 100))  # Limit to first 100 folders\n",
        "\n",
        "    for video_folder in tqdm(video_folders, desc=f\"Processing {folder_path}\"):\n",
        "        video_path = os.path.join(folder_path, video_folder)\n",
        "        if not os.path.isdir(video_path):\n",
        "            continue\n",
        "\n",
        "        # Process all frames (100 frames) inside each folder\n",
        "        for img_name in sorted(os.listdir(video_path)):\n",
        "            if not img_name.endswith('.jpg'):\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(video_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img_pil = Image.fromarray(img_rgb)\n",
        "            img_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                embedding = model(img_tensor).cpu().numpy().flatten()  # shape: (512,)\n",
        "\n",
        "            # Append the embedding and label to lists\n",
        "            all_embeddings.append(embedding)\n",
        "            all_labels.append(label)\n",
        "\n",
        "# Convert to arrays\n",
        "X = np.array(all_embeddings)  # shape: (num_images, 512)\n",
        "y = np.array(all_labels)      # shape: (num_images,)\n",
        "\n",
        "# Save embeddings and labels to Google Drive\n",
        "save_path = '/content/drive/MyDrive/embeddings_and_labels/'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save embeddings and labels to Google Drive\n",
        "np.save(os.path.join(save_path, \"all_embeddings.npy\"), X)\n",
        "np.save(os.path.join(save_path, \"all_labels.npy\"), y)\n",
        "\n",
        "print(f\"âœ… Finished processing. Embeddings shape: {X.shape}, Labels shape: {y.shape}\")\n"
      ],
      "metadata": {
        "id": "iLnUOiTzSjy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for v2\n"
      ],
      "metadata": {
        "id": "2qzITFfISsHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "from tqdm import tqdm\n",
        "from itertools import islice  # Import for limiting folder count\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Load model\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "\n",
        "# Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "# Base paths\n",
        "data_sources = {\n",
        "    \"/content/drive/MyDrive/FaceForensicsData/frames_for_original_videos\": 0,   # Real\n",
        "    \"/content/drive/MyDrive/FaceForensicsData/frames_for_FaceSwap\": 1 # Fake\n",
        "}\n",
        "\n",
        "# Hold all embeddings and labels\n",
        "all_embeddings = []\n",
        "all_labels = []\n",
        "\n",
        "# Process only the first 100 folders from both real and fake datasets\n",
        "for folder_path, label in data_sources.items():\n",
        "    # Use islice to limit the number of folders processed (100 folders from each category)\n",
        "    video_folders = list(islice(sorted(os.listdir(folder_path)), 100))  # Limit to first 100 folders\n",
        "\n",
        "    for video_folder in tqdm(video_folders, desc=f\"Processing {folder_path}\"):\n",
        "        video_path = os.path.join(folder_path, video_folder)\n",
        "        if not os.path.isdir(video_path):\n",
        "            continue\n",
        "\n",
        "        # Process all frames (100 frames) inside each folder\n",
        "        for img_name in sorted(os.listdir(video_path)):\n",
        "            if not img_name.endswith('.jpg'):\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(video_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img_pil = Image.fromarray(img_rgb)\n",
        "            img_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                embedding = model(img_tensor).cpu().numpy().flatten()  # shape: (512,)\n",
        "\n",
        "            # Append the embedding and label to lists\n",
        "            all_embeddings.append(embedding)\n",
        "            all_labels.append(label)\n",
        "\n",
        "# Convert to arrays\n",
        "X = np.array(all_embeddings)  # shape: (num_images, 512)\n",
        "y = np.array(all_labels)      # shape: (num_images,)\n",
        "\n",
        "# Save embeddings and labels to Google Drive\n",
        "save_path = '/content/drive/MyDrive/embeddings_and_labels/'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save embeddings and labels to Google Drive as v2 versions\n",
        "np.save(os.path.join(save_path, \"v2_embeddings.npy\"), X)\n",
        "np.save(os.path.join(save_path, \"v2_labels.npy\"), y)\n",
        "\n",
        "print(f\"âœ… Finished processing. Embeddings shape: {X.shape}, Labels shape: {y.shape}\")\n"
      ],
      "metadata": {
        "id": "7FgcUAo9StOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5Q18eDD_RplJ"
      }
    }
  ]
}